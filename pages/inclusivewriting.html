<div class="col-sm-12">
    
<h2>Inclusion and Diversity in Writing</h2>

  <p>As a large scientific and technical community that has a direct impact on many people from 
    different backgrounds around the world, Diversity and Inclusion are crucial for the data management 
    community. ACM explains these goals as follows. Diversity is achieved when the individuals around 
    the table are drawn from a variety of backgrounds and experience, leading to a breadth of viewpoints, 
    reasoning, and approaches (also referred to as "the who"). Inclusion is achieved when the environment 
    is characterized by behaviors that welcome and embrace diversity ("the how"). Both are important in 
    our writing and other forms of communication such as posters and talks.

  <h3>Inclusion</h3>
  <p>Be mindful of not using language or examples that further the marginalization, stereotyping, or 
    erasure of any group of people, especially historically marginalized and/or under-represented groups 
    (URGs) in computing. Of course, exclusionary or indifferent treatment can arise unintentionally. 
    Be vigilant and actively guard against such issues in your writing. Reviewers will also be empowered 
    to monitor and demand changes if such issues arise in your submissions. Here are some examples of 
    such issues for your benefit:

  <h4>Examples of exclusionary and other non-inclusive writing to consider avoiding:</h4>

  <ul>
    <li><b>Implicit assumption:</b> An example of database integrity constraints: "Every person has a 
      mother and a father." This example is exclusionary and potentially hurtful to people from 
      single-parent households and people with same-sex parents.

    <li><b>Oppressive terminology:</b> Using the term "Master-Slave" to describe a distributed data system 
      architecture. This can be hurtful to people whose families have suffered the inhumanity of enslavement. 
      A good source of alternative terms to oppressive language often used in computer science can be found 
      in <a href="https://tools.ietf.org/id/draft-knodel-terminology-00.html#rfc.section.1.1.1">this article<a/>.

      <li><b>Marginalization of URGs:</b> An example of attribute domains: "The Gender attribute is either 
      Male or Female." This example is exclusionary and potentially hurtful to people who are intersex, 
      transgender, third gender, two-spirit, agender, or have other non-binary gender identities.

      <li><b>Lack of accessibility:</b> Using color alone to convey information in a plot when good 
      alternative data visualization schemes exist. This can be exclusionary to people who are 
      color-blind. Please consider using patterns, symbols and textures to emphasize and contrast 
      visual elements in graphs and figures, rather than using colors alone. Use a color-blind 
      friendly palette that is designed with accessibility for visually impaired people. Avoid bad 
      color combinations such as green/red or blue/purple.

      <li><b>Stereotyping:</b> Reinforcing gender stereotypes in names or examples of roles, e.g., using 
      only feminine names or presentations for personal secretary or assistant roles.
  </ul>
  
      
<h3>Diversity</h3>
<p>Going further, please also consider actively raising the representation of URGs in your writing. 
  Diversity of representation helps create an environment and community culture that could ultimately 
  make our field more welcoming and attractive to people from URGs. This is a small but crucial step 
  you can take towards celebrating and improving our communityâ€™s diversity.

<h4>Examples of infusing diversity into writing to consider adopting:</h4>

  <ul>
    <li><b>Embracing different cultures:</b> Names of people are a visible way to enhance diversity 
      of representation in writing. Instead of reusing overused names in computing such as Alice and 
      Bob, consider using names from a variety of languages, cultures, and nationalities, e.g., 
      Alvarez and Bano. Avail of the many online resources on this front for ideas, e.g., 
      <a href="https://en.wikipedia.org/wiki/Category:Names_by_culture">this article</a> on names 
      across different cultures.

    <li><b>Embracing differences in figures:</b> Depictions of people or people-like icons in 
      illustrations are also a good avenue to enhance diversity of representation. Consider 
      depicting people of different gender presentations, skin colors, ability status, and other 
      visible attributes of people.

    <li><b>Embracing gender diversity in pronouns:</b> Consider using a variety of gender pronouns 
      across your named examples consciously, including "he/him/his," "she/her/hers," and 
      "they/them/theirs". Likewise, consider using gender-neutral nouns when referring to generic 
      roles, e.g., "chairperson" or just "chair" instead of "chairman," and gender-neutral pronouns 
      for such roles.
   </ul>

<h3>Responsibility</h3>
<p>Finally, if your work involves data-driven techniques that make decisions about people, 
  please consider explicitly discussing whether it may lead to disparate impact on different 
  groups, especially URGs. Consider discussing the ethical and societal implications. 
  For example, see this article discussing the potential for disparate impact of facial 
  recognition in healthcare and strategies to avoid or reduce harm. This SIGMOD Blog article 
  also gives a comprehensive overview of various dimensions and approaches for responsible 
  application of data management ideas. We hope our community can help permeate this culture 
  of responsibility and awareness about potentially harmful unintended negative consequences 
  of our work within the larger computing landscape.



  <h3>Acknowledgments and Further Reading</h3>
   <ul>
     <li>ACM Diversity and Inclusion: <a href="https://www.acm.org/diversity-inclusion">Webpage</a>
     <li>ACM SIGMOD Blog article on "Data, Responsibly": <a href="http://wp.sigmod.org/?p=1900">Webpage</a>
    <li>AMA Journal of Ethics article on "What Are Important Ethical Implications of Using Facial Recognition Technology in Health Care?": 
      <a href="https://journalofethics.ama-assn.org/article/what-are-important-ethical-implications-using-facial-recognition-technology-health-care/2019-02">Webpage</a>
    <li>Article on "Inclusive CS Examples": <a href="https://medium.com/@arunis100/inclusive-cs-examples-b5f40e003815">Webpage</a>
    <li>Article on "Terminology, Power and Oppressive Language": <a href="https://tools.ietf.org/id/draft-knodel-terminology-00.html">Webpage</a>
    <li>Helpful materials from UCSD CSE Diversity, Equity, and Inclusion Committee:: <a href="https://cse.ucsd.edu/diversity/videos">Webpage</a>
    <li>NeurIPS CFP on Broader Impact Statement: <a href="https://nips.cc/Conferences/2020/CallForPapers">Webpage</a>
    <li>Wikipedia listing of names across cultures: <a href="https://en.wikipedia.org/wiki/Category:Names_by_culture">Webpage</a>
  </ul>
  
<h3>More Acknowledgments</h3>
This document was originally created for SIGMOD 2021. We thank the SIGMOD 2021 PC Chairs and Web Chair for their feedback or dissemination.

</div>
